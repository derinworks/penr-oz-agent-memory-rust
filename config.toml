[server]
host = "127.0.0.1"
port = 8080

[embedding]
default_provider = "ollama"

[embedding.providers.ollama]
type = "ollama"
base_url = "http://localhost:11434"
model = "nomic-embed-text"

[embedding.providers.openai]
type = "openai"
base_url = "https://api.openai.com"
api_key = ""
model = "text-embedding-3-small"
# auth_scheme = "bearer"          # default; uses Authorization: Bearer <api_key>
# embeddings_path = "/v1/embeddings"  # default

[embedding.providers.claude]
type = "claude"
base_url = "https://api.anthropic.com"
api_key = ""
model = "voyage-3"

# Example: Azure OpenAI provider (OpenAI-compatible with different auth and path)
# [embedding.providers.azure]
# type = "openai"
# base_url = "https://<resource>.openai.azure.com"
# api_key = ""
# model = "text-embedding-3-small"
# auth_scheme = "api-key"
# embeddings_path = "/openai/deployments/<deployment>/embeddings?api-version=2024-02-01"

[qdrant]
# URL of the Qdrant instance (Docker default: http://localhost:6334)
# Override with QDRANT_URL environment variable.
url = "http://localhost:6334"
# Collection to store agent memories in.
# Override with QDRANT_COLLECTION environment variable.
collection = "agent_memory"
# Dimensionality must match the embedding model output.
# nomic-embed-text (ollama default) → 768
# text-embedding-3-small (openai)  → 1536
# voyage-3 (claude/anthropic)      → 1024
dimensions = 768
# api_key = ""   # Uncomment for Qdrant Cloud or auth-enabled instances.
                 # Override with QDRANT_API_KEY environment variable.
